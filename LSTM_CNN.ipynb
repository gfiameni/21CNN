{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network in 2D and 3D lightcones\n",
    "\n",
    "There are several ideas we would like to explore, concerning RNN networks.\n",
    "\n",
    "1. Compessing spacial data to N parameters with CNN, with network weights independent of time (redshift) and feeding those to RNN network which in every step tries to predict astrophysical parameters, and then weight somehow the sum all of those in the loss function.\n",
    "2. Using the whole CNN as a part of RNN network which updates it's weights in each iteration\n",
    "3. Some hybrid of usual convolution in spacial dimensions and WaveNet-like convolutions in time dimension\n",
    "\n",
    "In 1. and 2. for RNN part, we use LSTM cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import tensorflow as tf\n",
    "# os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "\n",
    "\n",
    "# #setting up GPU\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 1. #setting the percentage of GPU usage\n",
    "config.gpu_options.visible_device_list = \"0\" #for picking only some devices\n",
    "# config.gpu_options.allow_growth = True\n",
    "\n",
    "#passing tf session to keras!\n",
    "# from keras.backend.tensorflow_backend import set_session\n",
    "tf.compat.v1.keras.backend.set_session(tf.compat.v1.Session(config=config)) \n",
    "\n",
    "# from keras import backend as K\n",
    "tf.keras.backend.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#working with sliced data shape (10000, 4, 25, 25, ~500)\n",
    "DataLoc = \"../data/\"\n",
    "XName = \"data3D_boxcar444_sliced22_float32.npy\"\n",
    "YName = \"databaseParams_float32.npy\"\n",
    "YbackupName = \"databaseParams_min_max.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 4)\n",
      "{\n",
      "    \"parameters\": [\n",
      "        \"ZETA\",\n",
      "        \"TVIR_MIN\",\n",
      "        \"L_X\",\n",
      "        \"NU_X_THRESH\"\n",
      "    ],\n",
      "    \"min\": [\n",
      "        10.023063659667969,\n",
      "        4.000161170959473,\n",
      "        38.00041961669922,\n",
      "        100.13026428222656\n",
      "    ],\n",
      "    \"max\": [\n",
      "        249.9544677734375,\n",
      "        5.998933792114258,\n",
      "        41.99989700317383,\n",
      "        1499.37109375\n",
      "    ]\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.92404807, 0.92404807, 0.92404807, 0.92404807], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = np.load(DataLoc+YName)\n",
    "print(Y.shape)\n",
    "with open(DataLoc+YbackupName, \"r\") as f:\n",
    "    Params = json.load(f)\n",
    "print(json.dumps(Params, indent=4))\n",
    "Params[\"min\"] = np.array(Params[\"min\"], dtype = np.float32)\n",
    "Params[\"max\"] = np.array(Params[\"max\"], dtype = np.float32)\n",
    "\n",
    "Y = (Y - Params[\"min\"]) / (Params[\"max\"] - Params[\"min\"])\n",
    "shape = Y.shape\n",
    "Y = Y[..., np.newaxis]\n",
    "Y = np.broadcast_to(Y, shape + (4,))\n",
    "Y = np.swapaxes(Y, -1, -2)\n",
    "Y.shape\n",
    "Y[23, :, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(DataLoc+XName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 4)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.swapaxes(X, 2, 4)\n",
    "X = X.reshape(-1, X.shape[-3], X.shape[-2], X.shape[-1])\n",
    "Y = Y.reshape(-1, Y.shape[-1])\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate array with shape (32000, 526, 25, 25) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-0e9c0fc79b59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutilities3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbasicTDT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbasicTDT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/media/yqin/81614149-2ed8-4c76-82e1-c46763d086fa/pregi/21CNN/utilities3.py\u001b[0m in \u001b[0;36mbasicTDT\u001b[0;34m(X, Y, pTrain, pVal, pTest, seed)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mtdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mdX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindexArray\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mdY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindexArray\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mdX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRState\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate array with shape (32000, 526, 25, 25) and data type float32"
     ]
    }
   ],
   "source": [
    "from utilities3 import basicTDT\n",
    "Xtrain, Ytrain, Xval, Yval, Xtest, Ytest = basicTDT(X, Y, 0.8, 0.1, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "RState = np.random.RandomState(seed=1312)\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.1, random_state=RState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, TimeDistributed, Dense\n",
    "from tensorflow.keras.layers import Conv3D, Conv2D, Conv1D\n",
    "from tensorflow.keras.layers import ConvLSTM2D\n",
    "from tensorflow.keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperParams1:\n",
    "    def __init__(\n",
    "        LossDecay = 0.9,\n",
    "        LossLength = 10,\n",
    "        ):\n",
    "        self.LossDecay = LossDecay\n",
    "        self.LossLength = LossLength\n",
    "        \n",
    "model1 = Sequential()\n",
    "model1.add\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
